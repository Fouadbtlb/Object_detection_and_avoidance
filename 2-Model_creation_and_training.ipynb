{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442721cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "!conda install -c conda-forge ipywidgets --yes\n",
    "!pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9591b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import *\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from Mydataset import *\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a128d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(join(paths[\"SCRIPTS_PATH\"],\"vision\")):\n",
    "    !git clone https://github.com/pytorch/vision {join(paths[\"SCRIPTS_PATH\"],\"vision\")}\n",
    "if not os.path.exists(join(paths[\"SCRIPTS_PATH\"],\"coco\")):\n",
    "    !git clone https://github.com/cocodataset/cocoapi {join(paths[\"SCRIPTS_PATH\"],\"coco\")}\n",
    "    !cd Pytorch/scripts/coco/PythonAPI && python3 setup.py build_ext install\n",
    "    \n",
    "join(paths[\"SCRIPTS_PATH\"],\"vision\",\"references\",\"detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r Pytorch/scripts/vision/references/detection/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5afa204",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES=[\"Dog\",\"Motorcycle\", \"Van\", \"Bus\", \"Bicycle\", \"Car\",\"Person\",\"Man\",\"Truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9d2b1",
   "metadata": {},
   "source": [
    "# 1. Download pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_faster_rcnn=models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=False)\n",
    "my_faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e15036",
   "metadata": {},
   "source": [
    "**1.1 Changing the last layer to adapt it to our classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(CLASSES)\n",
    "in_features = my_faster_rcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "my_faster_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "my_faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce93cb8",
   "metadata": {},
   "source": [
    "# 2. see and exmple and test our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path=os.path.join(paths['ANNOTATION_TRAIN_PATH'],\"annotation.txt\")\n",
    "dataset=Mydataset(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959dc618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map=dataset.get_class_map()\n",
    "a_file = join(paths['ANNOTATION_PATH'],\"classes.txt\")\n",
    "import json\n",
    "with open(a_file, 'w') as convert_file:\n",
    "    convert_file.write(json.dumps(class_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae489dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57488e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_val=os.path.join(paths['ANNOTATION_VAL_PATH'],\"annotation.txt\")\n",
    "dataset_val=Mydataset(df_path_val, 720, 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(x): \n",
    "    return tuple(zip(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "images,targets = next(iter(data_loader_train))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ada2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict = my_faster_rcnn(images,targets)   # Returns losses and detections\n",
    "sum(loss for loss in loss_dict.values()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a983dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images,targets = next(iter(data_loader_train))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "my_faster_rcnn.eval()\n",
    "\n",
    "predictions = my_faster_rcnn(images)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3cdfb",
   "metadata": {},
   "source": [
    "# 3. training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb59725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision.models.detection.mask_rcnn\n",
    "import utils\n",
    "from coco_eval import CocoEvaluator\n",
    "from coco_utils import get_coco_api_from_dataset\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq, scaler=None):\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter(\"lr\", utils.SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
    "    header = f\"Epoch: [{epoch}]\"\n",
    "    \n",
    "    loss_classifier =[]\n",
    "    loss_box_reg=[]\n",
    "    loss_objectness=[]\n",
    "    loss_rpn_box_reg=[]\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1.0 / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters)\n",
    "\n",
    "    loss_to_plot=[]\n",
    "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            loss_to_plot.append(losses.item())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(f\"Loss is {loss_value}, stopping training\")\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if scaler is not None:\n",
    "            scaler.scale(losses).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    return metric_logger,loss_to_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad864a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from engine import train_one_epoch\n",
    "import utils\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"We will be using \",device)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=3, shuffle=True, num_workers=3,\n",
    "    collate_fn=collate)\n",
    "\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=1, shuffle=False, num_workers=3,\n",
    "    collate_fn=collate)\n",
    "\n",
    "# move model to the right device\n",
    "my_faster_rcnn.to(device)\n",
    "\n",
    "    # construct an optimizer\n",
    "params = [p for p in my_faster_rcnn.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "    # and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=3,\n",
    "                                                   gamma=0.1)\n",
    "\n",
    "# let's train it for 20 epochs\n",
    "num_epochs = 20\n",
    "total_loss_to_plot=[]\n",
    "loss_axis=[]\n",
    "loss_classifier=[]\n",
    "loss_box_reg=[]\n",
    "loss_objectness=[]\n",
    "loss_rpn_box_reg=[]\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 100 iterations\n",
    "    metric_logger,loss=train_one_epoch(my_faster_rcnn, optimizer, data_loader, device, epoch, print_freq=100)\n",
    "    \n",
    "    \n",
    "    total_loss_to_plot.append(loss)\n",
    "    loss_list = metric_logger.meters.get('loss')\n",
    "    loss_classifier_list=metric_logger.meters.get('loss_classifier')\n",
    "    loss_box_reg_list=metric_logger.meters.get('loss_box_reg')\n",
    "    loss_objectness_list=metric_logger.meters.get('loss_objectness')\n",
    "    loss_rpn_box_reg_list=metric_logger.meters.get('loss_rpn_box_reg')\n",
    "    \n",
    "    loss_axis.append(loss_list.value)\n",
    "    loss_classifier.append(loss_classifier_list.value)\n",
    "    loss_box_reg.append(loss_box_reg_list.value)\n",
    "    loss_objectness.append(loss_objectness_list.value)\n",
    "    loss_rpn_box_reg.append(loss_rpn_box_reg_list.value)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "\n",
    "print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce339145",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_to_plot=np.array(total_loss_to_plot)\n",
    "mean_of_losses=total_loss_to_plot.mean(axis=1)\n",
    "fig, axs = plt.subplots(3,figsize=(15, 10))\n",
    "\n",
    "\n",
    "axs[0].plot(total_loss_to_plot)\n",
    "axs[0].set_title('total Losses for each epochs')\n",
    "\n",
    "axs[1].plot(total_loss_to_plot[0])\n",
    "axs[1].set_title('total Loss during the first epoch')\n",
    "\n",
    "axs[2].plot(mean_of_losses)\n",
    "axs[2].set_title('mean of total Loss for all epochs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae93e1",
   "metadata": {},
   "source": [
    "# 4. save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(my_faster_rcnn.state_dict(), join(paths[\"MODEL_PATH\"],\"dict_pretrained_faster_rcnn.h\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22abe320",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(my_faster_rcnn,join(paths[\"MODEL_PATH\"],\"full_pretrained_faster_rcnn.h\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (final_results)",
   "language": "python",
   "name": "final_results"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
